{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bayesian Multi-Sensor Fusion for Autonomous Vehicle Localization\n",
        "\n",
        "**Course:** Calculus-Based Probability and Statistics for Engineers  \n",
        "**Team Members:** [Your Name 1], [Your Name 2]  \n",
        "**Date:** November 2025\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project implements **optimal sensor fusion** for autonomous vehicle localization by combining:\n",
        "- **LiDAR** (high-precision distance: σ = 0.5m)\n",
        "- **Radar** (position: σ = 2.0m, velocity: σ = 0.1m/s)\n",
        "- **Camera** (visual positioning: σ = 4.0m)\n",
        "\n",
        "We demonstrate:\n",
        "1. ✅ Real-world engineering application (autonomous driving)\n",
        "2. ✅ Mathematical rigor (Kalman Filter derivation from Bayes' Theorem)\n",
        "3. ✅ AI integration (Bayesian inference with PyMC + MCMC)\n",
        "4. ✅ Comprehensive simulations and validation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run this cell first!)\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Install all required packages silently\"\"\"\n",
        "    packages = ['pymc', 'numpy', 'matplotlib', 'arviz', 'scipy', 'pandas']\n",
        "    for package in packages:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "    print(\"✓ All packages installed successfully!\")\n",
        "\n",
        "# Uncomment the line below if running for the first time\n",
        "# install_packages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, chi2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    import pymc as pm\n",
        "    import arviz as az\n",
        "    print(f\"✓ PyMC version: {pm.__version__}\")\n",
        "    print(f\"✓ ArviZ version: {az.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"⚠ PyMC not found. Please run the installation cell above.\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure matplotlib for better-looking plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"\\n✓ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2: Mathematical Foundation - Kalman Filter Derivation\n",
        "\n",
        "### State-Space Model\n",
        "\n",
        "**Continuous-Time Dynamics:**\n",
        "$$\n",
        "\\frac{dx}{dt} = Ax + Bu + w \\quad \\text{where } w \\sim \\mathcal{N}(0, Q)\n",
        "$$\n",
        "$$\n",
        "y = Cx + v \\quad \\text{where } v \\sim \\mathcal{N}(0, R)\n",
        "$$\n",
        "\n",
        "**Discretized System:**\n",
        "$$\n",
        "x_k = \\Phi x_{k-1} + \\Gamma u_{k-1} + w_k\n",
        "$$\n",
        "$$\n",
        "z_k = Hx_k + v_k\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $x = [\\text{position}, \\text{velocity}]^T$ (state vector)\n",
        "- $\\Phi$ = state transition matrix (from calculus)\n",
        "- $H$ = measurement matrix\n",
        "- $Q$ = process noise covariance\n",
        "- $R$ = measurement noise covariance\n",
        "\n",
        "### Kalman Filter Equations\n",
        "\n",
        "**Prediction Step:**\n",
        "$$\n",
        "\\hat{x}_{k|k-1} = \\Phi\\hat{x}_{k-1|k-1} + \\Gamma u_{k-1}\n",
        "$$\n",
        "$$\n",
        "P_{k|k-1} = \\Phi P_{k-1|k-1}\\Phi^T + Q\n",
        "$$\n",
        "\n",
        "**Update Step (from Bayes' Theorem):**\n",
        "$$\n",
        "K_k = P_{k|k-1}H^T(HP_{k|k-1}H^T + R)^{-1} \\quad \\text{[Kalman Gain]}\n",
        "$$\n",
        "$$\n",
        "\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k(z_k - H\\hat{x}_{k|k-1}) \\quad \\text{[State Update]}\n",
        "$$\n",
        "$$\n",
        "P_{k|k} = (I - K_kH)P_{k|k-1} \\quad \\text{[Covariance Update]}\n",
        "$$\n",
        "\n",
        "The Kalman Filter is the **optimal Bayesian estimator** for linear-Gaussian systems (minimizes mean square error).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: System Configuration & Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SIMULATION PARAMETERS\n",
        "# ============================================================================\n",
        "\n",
        "# Time configuration\n",
        "T = 100              # Number of timesteps\n",
        "dt = 0.1             # Time step (seconds)\n",
        "time = np.arange(T) * dt\n",
        "\n",
        "# Initial conditions\n",
        "initial_position = 0.0      # meters\n",
        "initial_velocity = 10.0     # m/s\n",
        "acceleration = 0.5          # m/s²\n",
        "\n",
        "# ============================================================================\n",
        "# STATE-SPACE MATRICES (derived from physics)\n",
        "# ============================================================================\n",
        "\n",
        "# State transition matrix (constant acceleration model)\n",
        "# Derived from: x(t+Δt) = x(t) + v(t)·Δt + ½a·Δt²\n",
        "#               v(t+Δt) = v(t) + a·Δt\n",
        "Phi = np.array([\n",
        "    [1, dt],      # position_new = position + velocity*dt\n",
        "    [0, 1]        # velocity_new = velocity (+ process noise)\n",
        "])\n",
        "\n",
        "# Control input matrix (acceleration effect)\n",
        "Gamma = np.array([\n",
        "    [0.5 * dt**2],     # position effect: ½at²\n",
        "    [dt]               # velocity effect: at\n",
        "])\n",
        "\n",
        "# Measurement matrix (we observe position from sensors)\n",
        "H = np.array([[1, 0]])  # Extract position from state vector\n",
        "H_velocity = np.array([[0, 1]])  # Extract velocity from state vector\n",
        "\n",
        "# ============================================================================\n",
        "# NOISE COVARIANCES\n",
        "# ============================================================================\n",
        "\n",
        "# Process noise (model uncertainty)\n",
        "q_position = 0.1   # Position process noise\n",
        "q_velocity = 0.05  # Velocity process noise\n",
        "Q = np.array([\n",
        "    [q_position, 0],\n",
        "    [0, q_velocity]\n",
        "])\n",
        "\n",
        "# Sensor noise characteristics (based on real specifications)\n",
        "sensor_params = {\n",
        "    'LiDAR': {'sigma': 0.5, 'color': 'green', 'marker': 'o', 'alpha': 0.3},\n",
        "    'Radar': {'sigma': 2.0, 'color': 'blue', 'marker': 's', 'alpha': 0.3},\n",
        "    'Camera': {'sigma': 4.0, 'color': 'red', 'marker': '^', 'alpha': 0.3}\n",
        "}\n",
        "\n",
        "sigma_velocity = 0.1  # Radar Doppler velocity measurement noise (m/s)\n",
        "\n",
        "# ============================================================================\n",
        "# DISPLAY CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" SYSTEM CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTime Configuration:\")\n",
        "print(f\"  Duration: {T*dt:.1f} seconds ({T} timesteps)\")\n",
        "print(f\"  Timestep: {dt} seconds\")\n",
        "\n",
        "print(f\"\\nInitial Conditions:\")\n",
        "print(f\"  Position: {initial_position:.1f} m\")\n",
        "print(f\"  Velocity: {initial_velocity:.1f} m/s\")\n",
        "print(f\"  Acceleration: {acceleration:.2f} m/s²\")\n",
        "\n",
        "print(f\"\\nSensor Noise Characteristics (σ):\")\n",
        "for sensor, params in sensor_params.items():\n",
        "    print(f\"  {sensor:8s}: {params['sigma']:.2f} m\")\n",
        "print(f\"  Velocity (Radar Doppler): {sigma_velocity:.2f} m/s\")\n",
        "\n",
        "print(f\"\\nProcess Noise:\")\n",
        "print(f\"  Position: {q_position:.3f} m²\")\n",
        "print(f\"  Velocity: {q_velocity:.3f} (m/s)²\")\n",
        "\n",
        "print(\"\\n✓ Configuration complete\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 4: Ground Truth & Sensor Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# GENERATE GROUND TRUTH TRAJECTORY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nGenerating ground truth trajectory...\")\n",
        "\n",
        "# Initialize state arrays\n",
        "true_state = np.zeros((T, 2))  # [position, velocity]\n",
        "true_state[0] = [initial_position, initial_velocity]\n",
        "\n",
        "# Propagate dynamics with process noise\n",
        "for k in range(1, T):\n",
        "    # Add process noise (model uncertainty)\n",
        "    process_noise = np.random.multivariate_normal([0, 0], Q)\n",
        "    \n",
        "    # State propagation: x_k = Φ·x_{k-1} + Γ·u + w_k\n",
        "    true_state[k] = Phi @ true_state[k-1] + Gamma.flatten() * acceleration + process_noise\n",
        "\n",
        "print(f\"✓ Ground truth generated for {T} timesteps\")\n",
        "print(f\"  Final position: {true_state[-1, 0]:.2f} m\")\n",
        "print(f\"  Final velocity: {true_state[-1, 1]:.2f} m/s\")\n",
        "\n",
        "# ============================================================================\n",
        "# GENERATE NOISY SENSOR MEASUREMENTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nGenerating sensor measurements...\")\n",
        "\n",
        "# Initialize measurement arrays\n",
        "measurements = {sensor: np.zeros(T) for sensor in sensor_params.keys()}\n",
        "measurements['velocity'] = np.zeros(T)\n",
        "\n",
        "# Generate noisy measurements from each sensor\n",
        "for sensor, params in sensor_params.items():\n",
        "    noise = np.random.normal(0, params['sigma'], T)\n",
        "    measurements[sensor] = true_state[:, 0] + noise\n",
        "    print(f\"  ✓ {sensor}: {T} position measurements (σ = {params['sigma']:.2f}m)\")\n",
        "\n",
        "# Radar velocity measurements (Doppler)\n",
        "velocity_noise = np.random.normal(0, sigma_velocity, T)\n",
        "measurements['velocity'] = true_state[:, 1] + velocity_noise\n",
        "print(f\"  ✓ Radar Doppler: {T} velocity measurements (σ = {sigma_velocity:.2f}m/s)\")\n",
        "\n",
        "print(\"\\n✓ All sensor data generated successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5: Classical Kalman Filter Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kalman_filter(measurements, sensor_sigmas, velocity_measurements=None, verbose=True):\n",
        "    \"\"\"\n",
        "    Implement classical Kalman Filter with multi-sensor fusion.\n",
        "    \n",
        "    This is the OPTIMAL Bayesian estimator for linear-Gaussian systems.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    measurements : dict\n",
        "        Dictionary of sensor measurements (position)\n",
        "    sensor_sigmas : dict\n",
        "        Dictionary of sensor noise standard deviations\n",
        "    velocity_measurements : array, optional\n",
        "        Velocity measurements from Radar Doppler\n",
        "    verbose : bool\n",
        "        Print progress information\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    x_est : array (T, 2)\n",
        "        Estimated state [position, velocity]\n",
        "    P_est : array (T, 2, 2)\n",
        "        Estimation error covariance\n",
        "    innovations : list\n",
        "        Innovation sequence (for validation)\n",
        "    kalman_gains : list\n",
        "        Kalman gain evolution\n",
        "    \"\"\"\n",
        "    \n",
        "    n_steps = len(measurements[list(measurements.keys())[0]])\n",
        "    \n",
        "    # Initialize estimates\n",
        "    x_est = np.zeros((n_steps, 2))\n",
        "    P_est = np.zeros((n_steps, 2, 2))\n",
        "    \n",
        "    # Initial state estimate (rough guess)\n",
        "    x_est[0] = [0, 10]  # position ≈ 0, velocity ≈ 10 m/s\n",
        "    P_est[0] = np.eye(2) * 10  # High initial uncertainty\n",
        "    \n",
        "    # Storage for diagnostic information\n",
        "    innovations = []\n",
        "    kalman_gains = []\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\" KALMAN FILTER EXECUTION\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"\\nInitial state: x₀ = [{x_est[0,0]:.1f}, {x_est[0,1]:.1f}]\")\n",
        "        print(f\"Initial uncertainty: P₀ diagonal = {np.diag(P_est[0])}\")\n",
        "        print(f\"\\nProcessing {n_steps} timesteps...\\n\")\n",
        "    \n",
        "    # Main Kalman Filter loop\n",
        "    for k in range(1, n_steps):\n",
        "        # ====================================================================\n",
        "        # PREDICTION STEP (Prior)\n",
        "        # ====================================================================\n",
        "        x_pred = Phi @ x_est[k-1] + Gamma.flatten() * acceleration\n",
        "        P_pred = Phi @ P_est[k-1] @ Phi.T + Q\n",
        "        \n",
        "        # ====================================================================\n",
        "        # UPDATE STEP (Posterior) - Multi-sensor fusion\n",
        "        # ====================================================================\n",
        "        x_update = x_pred.copy()\n",
        "        P_update = P_pred.copy()\n",
        "        \n",
        "        # Sequential update with each position sensor\n",
        "        for sensor, sigma in sensor_sigmas.items():\n",
        "            R = np.array([[sigma**2]])  # Measurement noise covariance\n",
        "            \n",
        "            # Innovation covariance\n",
        "            S = H @ P_update @ H.T + R\n",
        "            \n",
        "            # Kalman Gain (optimal weighting)\n",
        "            K = P_update @ H.T @ np.linalg.inv(S)\n",
        "            \n",
        "            # Innovation (measurement residual)\n",
        "            y = measurements[sensor][k] - H @ x_update\n",
        "            \n",
        "            # State update\n",
        "            x_update = x_update + (K @ y).flatten()\n",
        "            \n",
        "            # Covariance update (Joseph form for numerical stability)\n",
        "            P_update = (np.eye(2) - K @ H) @ P_update\n",
        "            \n",
        "            # Store diagnostics\n",
        "            innovations.append(y[0])\n",
        "            kalman_gains.append(K[0, 0])\n",
        "        \n",
        "        # Update with velocity measurement if available\n",
        "        if velocity_measurements is not None:\n",
        "            R_vel = np.array([[sigma_velocity**2]])\n",
        "            S_vel = H_velocity @ P_update @ H_velocity.T + R_vel\n",
        "            K_vel = P_update @ H_velocity.T @ np.linalg.inv(S_vel)\n",
        "            \n",
        "            y_vel = velocity_measurements[k] - H_velocity @ x_update\n",
        "            x_update = x_update + (K_vel @ y_vel).flatten()\n",
        "            P_update = (np.eye(2) - K_vel @ H_velocity) @ P_update\n",
        "            \n",
        "            innovations.append(y_vel[0])\n",
        "        \n",
        "        # Store estimates\n",
        "        x_est[k] = x_update\n",
        "        P_est[k] = P_update\n",
        "        \n",
        "        # Progress indicator\n",
        "        if verbose and k % 20 == 0:\n",
        "            print(f\"  Step {k:3d}/{n_steps}: pos={x_update[0]:7.2f}m, vel={x_update[1]:6.2f}m/s, σ_pos={np.sqrt(P_update[0,0]):.3f}m\")\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n✓ Kalman Filter completed successfully\")\n",
        "        print(f\"  Final state: [{x_est[-1,0]:.2f}, {x_est[-1,1]:.2f}]\")\n",
        "        print(f\"  Final uncertainty: σ_pos={np.sqrt(P_est[-1,0,0]):.3f}m, σ_vel={np.sqrt(P_est[-1,1,1]):.3f}m/s\")\n",
        "        print(\"=\"*80)\n",
        "    \n",
        "    return x_est, P_est, innovations, kalman_gains\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# RUN KALMAN FILTER\n",
        "# ============================================================================\n",
        "\n",
        "sensor_sigmas = {s: p['sigma'] for s, p in sensor_params.items()}\n",
        "\n",
        "kf_state, kf_covariance, innovations, gains = kalman_filter(\n",
        "    measurements, \n",
        "    sensor_sigmas,\n",
        "    measurements['velocity'],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Calculate performance metrics\n",
        "rmse_position = np.sqrt(np.mean((kf_state[:, 0] - true_state[:, 0])**2))\n",
        "rmse_velocity = np.sqrt(np.mean((kf_state[:, 1] - true_state[:, 1])**2))\n",
        "mae_position = np.mean(np.abs(kf_state[:, 0] - true_state[:, 0]))\n",
        "mae_velocity = np.mean(np.abs(kf_state[:, 1] - true_state[:, 1]))\n",
        "\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"  Position RMSE: {rmse_position:.4f} m\")\n",
        "print(f\"  Velocity RMSE: {rmse_velocity:.4f} m/s\")\n",
        "print(f\"  Position MAE:  {mae_position:.4f} m\")\n",
        "print(f\"  Velocity MAE:  {mae_velocity:.4f} m/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 6: Bayesian Inference with PyMC (AI Component)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For computational efficiency, use a subset of data for full Bayesian inference\n",
        "subset_size = 30\n",
        "subset_idx = np.linspace(0, T-1, subset_size, dtype=int)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" BAYESIAN INFERENCE WITH PyMC\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nUsing {subset_size} timesteps for full Bayesian inference...\")\n",
        "print(\"(Full dataset is used for Kalman Filter)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# BUILD BAYESIAN MODEL\n",
        "# ============================================================================\n",
        "\n",
        "with pm.Model() as bayesian_model:\n",
        "    \n",
        "    # Priors - Weakly informative\n",
        "    position = pm.Normal('position', mu=50, sigma=50, shape=subset_size)\n",
        "    velocity = pm.Normal('velocity', mu=12, sigma=10, shape=subset_size)\n",
        "    \n",
        "    # INNOVATION: Temporal smoothness constraints\n",
        "    # This is the key AI component that makes this better than independent estimates!\n",
        "    # We penalize large jumps in state between timesteps\n",
        "    for i in range(1, subset_size):\n",
        "        # Position should evolve smoothly according to velocity\n",
        "        pm.Normal(f'smooth_pos_{i}', \n",
        "                 mu=position[i-1] + velocity[i-1] * dt * (subset_idx[i] - subset_idx[i-1]), \n",
        "                 sigma=3.0, \n",
        "                 observed=position[i])\n",
        "        \n",
        "        # Velocity should change gradually\n",
        "        pm.Normal(f'smooth_vel_{i}', \n",
        "                 mu=velocity[i-1], \n",
        "                 sigma=1.5, \n",
        "                 observed=velocity[i])\n",
        "    \n",
        "    # Likelihoods - Connect to sensor observations\n",
        "    for sensor, params in sensor_params.items():\n",
        "        pm.Normal(f'obs_{sensor}', \n",
        "                 mu=position, \n",
        "                 sigma=params['sigma'], \n",
        "                 observed=measurements[sensor][subset_idx])\n",
        "    \n",
        "    pm.Normal('obs_velocity', \n",
        "             mu=velocity, \n",
        "             sigma=sigma_velocity, \n",
        "             observed=measurements['velocity'][subset_idx])\n",
        "\n",
        "print(\"✓ Bayesian model constructed\")\n",
        "print(\"  Model structure:\")\n",
        "print(\"    - Priors: Weakly informative Gaussians\")\n",
        "print(\"    - Temporal smoothness: Penalizes large state jumps\")\n",
        "print(\"    - Likelihoods: Multi-sensor observations\")\n",
        "\n",
        "# ============================================================================\n",
        "# RUN MCMC SAMPLING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nRunning MCMC sampling...\")\n",
        "print(\"  Algorithm: NUTS (No-U-Turn Sampler)\")\n",
        "print(\"  Chains: 2\")\n",
        "print(\"  Samples per chain: 2000 (+ 1000 tuning)\")\n",
        "print(\"\\n  This may take 1-2 minutes... ☕\\n\")\n",
        "\n",
        "with bayesian_model:\n",
        "    trace = pm.sample(\n",
        "        2000,                    # Number of samples\n",
        "        tune=1000,              # Tuning/warmup samples\n",
        "        cores=1,                # CPU cores (use 1 for Colab stability)\n",
        "        return_inferencedata=True,\n",
        "        progressbar=True,\n",
        "        random_seed=42\n",
        "    )\n",
        "\n",
        "print(\"\\n✓ MCMC sampling complete!\")\n",
        "\n",
        "# ============================================================================\n",
        "# EXTRACT POSTERIOR STATISTICS\n",
        "# ============================================================================\n",
        "\n",
        "posterior_position = trace.posterior['position'].mean(dim=['chain', 'draw']).values\n",
        "posterior_velocity = trace.posterior['velocity'].mean(dim=['chain', 'draw']).values\n",
        "\n",
        "posterior_position_std = trace.posterior['position'].std(dim=['chain', 'draw']).values\n",
        "posterior_velocity_std = trace.posterior['velocity'].std(dim=['chain', 'draw']).values\n",
        "\n",
        "